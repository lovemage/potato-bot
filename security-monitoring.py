# security_module.py - å®‰å…¨æ¨¡çµ„

import hashlib
import secrets
import time
from datetime import datetime, timedelta
from functools import wraps
import re
from typing import Dict, List, Optional

class SecurityModule:
    """è™•ç†æ‰€æœ‰å®‰å…¨ç›¸é—œåŠŸèƒ½"""
    
    def __init__(self):
        self.rate_limits = {}  # é€Ÿç‡é™åˆ¶è¨˜éŒ„
        self.blocked_users = set()  # è¢«å°é–çš„ç”¨æˆ¶
        self.failed_attempts = {}  # å¤±æ•—å˜—è©¦è¨˜éŒ„
        
    def rate_limiter(self, max_calls: int = 10, window: int = 60):
        """é€Ÿç‡é™åˆ¶è£é£¾å™¨"""
        def decorator(func):
            @wraps(func)
            async def wrapper(update, context, *args, **kwargs):
                user_id = update.effective_user.id
                current_time = time.time()
                
                # åˆå§‹åŒ–ç”¨æˆ¶è¨˜éŒ„
                if user_id not in self.rate_limits:
                    self.rate_limits[user_id] = []
                
                # æ¸…ç†éæœŸè¨˜éŒ„
                self.rate_limits[user_id] = [
                    timestamp for timestamp in self.rate_limits[user_id]
                    if current_time - timestamp < window
                ]
                
                # æª¢æŸ¥é€Ÿç‡é™åˆ¶
                if len(self.rate_limits[user_id]) >= max_calls:
                    await update.message.reply_text(
                        "âš ï¸ è«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                    )
                    return
                
                # è¨˜éŒ„æ­¤æ¬¡èª¿ç”¨
                self.rate_limits[user_id].append(current_time)
                
                # åŸ·è¡ŒåŸå‡½æ•¸
                return await func(update, context, *args, **kwargs)
            
            return wrapper
        return decorator
    
    def check_user_blocked(self, user_id: int) -> bool:
        """æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦è¢«å°é–"""
        return user_id in self.blocked_users
    
    def block_user(self, user_id: int, reason: str = ""):
        """å°é–ç”¨æˆ¶"""
        self.blocked_users.add(user_id)
        # è¨˜éŒ„å°é–åŸå› å’Œæ™‚é–“
        with open('blocked_users.log', 'a') as f:
            f.write(f"{datetime.now()}: User {user_id} blocked. Reason: {reason}\n")
    
    def unblock_user(self, user_id: int):
        """è§£å°ç”¨æˆ¶"""
        self.blocked_users.discard(user_id)
    
    def validate_input(self, text: str, input_type: str) -> bool:
        """é©—è­‰ç”¨æˆ¶è¼¸å…¥"""
        validators = {
            'email': r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$',
            'phone': r'^\+?[1-9]\d{1,14}$',
            'transaction_hash': r'^[a-fA-F0-9]{64}$',
            'usdt_address': r'^T[a-zA-Z0-9]{33}$'  # TRC20 åœ°å€æ ¼å¼
        }
        
        pattern = validators.get(input_type)
        if pattern:
            return bool(re.match(pattern, text))
        
        return False
    
    def generate_secure_token(self, length: int = 32) -> str:
        """ç”Ÿæˆå®‰å…¨ä»¤ç‰Œ"""
        return secrets.token_urlsafe(length)
    
    def verify_payment_signature(self, data: Dict, signature: str, secret: str) -> bool:
        """é©—è­‰æ”¯ä»˜å›èª¿ç°½å"""
        # æ ¹æ“šæ”¯ä»˜å¹³å°çš„è¦å‰‡ç”Ÿæˆç°½å
        message = ''.join([str(data[key]) for key in sorted(data.keys())])
        expected_signature = hashlib.sha256(
            f"{message}{secret}".encode()
        ).hexdigest()
        
        return secrets.compare_digest(signature, expected_signature)
    
    async def anti_fraud_check(self, user_id: int, order_data: Dict) -> Dict:
        """åæ¬ºè©æª¢æŸ¥"""
        risk_score = 0
        risk_factors = []
        
        # æª¢æŸ¥æ–°ç”¨æˆ¶
        if order_data.get('is_new_user'):
            risk_score += 20
            risk_factors.append("æ–°ç”¨æˆ¶")
        
        # æª¢æŸ¥è¨‚å–®é‡‘é¡
        if order_data.get('amount', 0) > 100:
            risk_score += 30
            risk_factors.append("é«˜é¡è¨‚å–®")
        
        # æª¢æŸ¥è³¼è²·é »ç‡
        recent_orders = order_data.get('recent_orders_count', 0)
        if recent_orders > 5:
            risk_score += 40
            risk_factors.append("é »ç¹è³¼è²·")
        
        # æª¢æŸ¥å¤±æ•—æ”¯ä»˜è¨˜éŒ„
        failed_payments = self.failed_attempts.get(user_id, 0)
        if failed_payments > 3:
            risk_score += 50
            risk_factors.append("å¤šæ¬¡æ”¯ä»˜å¤±æ•—")
        
        return {
            'risk_score': risk_score,
            'risk_level': 'high' if risk_score > 60 else 'medium' if risk_score > 30 else 'low',
            'risk_factors': risk_factors,
            'action': 'block' if risk_score > 80 else 'review' if risk_score > 60 else 'pass'
        }
    
    def encrypt_sensitive_data(self, data: str, key: str) -> str:
        """åŠ å¯†æ•æ„Ÿæ•¸æ“š"""
        # ä½¿ç”¨ç°¡å–®çš„ XOR åŠ å¯†ç¤ºä¾‹ï¼Œå¯¦éš›æ‡‰ä½¿ç”¨æ›´å¼·çš„åŠ å¯†ç®—æ³•
        # å»ºè­°ä½¿ç”¨ cryptography åº«çš„ Fernet
        from cryptography.fernet import Fernet
        
        if not hasattr(self, '_fernet'):
            self._fernet = Fernet(Fernet.generate_key())
        
        return self._fernet.encrypt(data.encode()).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str, key: str) -> str:
        """è§£å¯†æ•æ„Ÿæ•¸æ“š"""
        if hasattr(self, '_fernet'):
            return self._fernet.decrypt(encrypted_data.encode()).decode()
        return ""

# monitoring_system.py - ç›£æ§ç³»çµ±

import psutil
import asyncio
from collections import deque
from datetime import datetime, timedelta

class MonitoringSystem:
    """ç³»çµ±ç›£æ§æ¨¡çµ„"""
    
    def __init__(self, alert_callback=None):
        self.metrics = {
            'response_times': deque(maxlen=1000),
            'error_count': 0,
            'success_count': 0,
            'active_users': set(),
            'daily_orders': deque(maxlen=30)
        }
        self.alert_callback = alert_callback
        self.alert_thresholds = {
            'response_time': 3.0,  # ç§’
            'error_rate': 0.1,  # 10%
            'cpu_usage': 80,  # ç™¾åˆ†æ¯”
            'memory_usage': 80  # ç™¾åˆ†æ¯”
        }
    
    async def log_request(self, user_id: int, command: str, response_time: float, success: bool):
        """è¨˜éŒ„è«‹æ±‚"""
        self.metrics['response_times'].append(response_time)
        self.metrics['active_users'].add(user_id)
        
        if success:
            self.metrics['success_count'] += 1
        else:
            self.metrics['error_count'] += 1
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦ç™¼é€è­¦å ±
        await self._check_alerts()
    
    async def _check_alerts(self):
        """æª¢æŸ¥ä¸¦ç™¼é€è­¦å ±"""
        # æª¢æŸ¥éŸ¿æ‡‰æ™‚é–“
        if self.metrics['response_times']:
            avg_response_time = sum(self.metrics['response_times']) / len(self.metrics['response_times'])
            if avg_response_time > self.alert_thresholds['response_time']:
                await self._send_alert(f"é«˜éŸ¿æ‡‰æ™‚é–“è­¦å ±: {avg_response_time:.2f}ç§’")
        
        # æª¢æŸ¥éŒ¯èª¤ç‡
        total_requests = self.metrics['success_count'] + self.metrics['error_count']
        if total_requests > 100:
            error_rate = self.metrics['error_count'] / total_requests
            if error_rate > self.alert_thresholds['error_rate']:
                await self._send_alert(f"é«˜éŒ¯èª¤ç‡è­¦å ±: {error_rate:.2%}")
    
    async def _send_alert(self, message: str):
        """ç™¼é€è­¦å ±"""
        if self.alert_callback:
            await self.alert_callback(message)
    
    def get_system_stats(self) -> Dict:
        """ç²å–ç³»çµ±çµ±è¨ˆä¿¡æ¯"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            'cpu_usage': cpu_percent,
            'memory_usage': memory.percent,
            'memory_available': memory.available / (1024 ** 3),  # GB
            'disk_usage': disk.percent,
            'disk_free': disk.free / (1024 ** 3),  # GB
            'active_users': len(self.metrics['active_users']),
            'total_requests': self.metrics['success_count'] + self.metrics['error_count'],
            'error_rate': self.metrics['error_count'] / max(1, self.metrics['success_count'] + self.metrics['error_count'])
        }
    
    async def generate_health_report(self) -> str:
        """ç”Ÿæˆå¥åº·å ±å‘Š"""
        stats = self.get_system_stats()
        
        report = f"""
ğŸ“Š ç³»çµ±å¥åº·å ±å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ–¥ï¸ ç³»çµ±è³‡æº:
â€¢ CPU ä½¿ç”¨ç‡: {stats['cpu_usage']:.1f}%
â€¢ å…§å­˜ä½¿ç”¨ç‡: {stats['memory_usage']:.1f}%
â€¢ å¯ç”¨å…§å­˜: {stats['memory_available']:.1f} GB
â€¢ ç¡¬ç›¤ä½¿ç”¨ç‡: {stats['disk_usage']:.1f}%
â€¢ å¯ç”¨ç©ºé–“: {stats['disk_free']:.1f} GB

ğŸ“ˆ é‹è¡Œçµ±è¨ˆ:
â€¢ æ´»èºç”¨æˆ¶: {stats['active_users']}
â€¢ ç¸½è«‹æ±‚æ•¸: {stats['total_requests']}
â€¢ éŒ¯èª¤ç‡: {stats['error_rate']:.2%}

ç‹€æ…‹: {'âš ï¸ éœ€è¦é—œæ³¨' if any([
    stats['cpu_usage'] > 80,
    stats['memory_usage'] > 80,
    stats['error_rate'] > 0.1
]) else 'âœ… é‹è¡Œæ­£å¸¸'}
        """
        
        return report
    
    async def cleanup_old_data(self, days: int = 30):
        """æ¸…ç†èˆŠæ•¸æ“š"""
        # å¯¦ç¾æ•¸æ“šæ¸…ç†é‚è¼¯
        pass

# backup_restore.py - å‚™ä»½èˆ‡æ¢å¾©

import shutil
import zipfile
from pathlib import Path

class BackupRestore:
    """å‚™ä»½èˆ‡æ¢å¾©ç³»çµ±"""
    
    def __init__(self, backup_dir: str = "backups"):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
    
    def create_backup(self, db_path: str, include_logs: bool = True) -> str:
        """å‰µå»ºå‚™ä»½"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"backup_{timestamp}"
        backup_path = self.backup_dir / backup_name
        backup_path.mkdir(exist_ok=True)
        
        # å‚™ä»½æ•¸æ“šåº«
        shutil.copy2(db_path, backup_path / "database.db")
        
        # å‚™ä»½æ—¥èªŒæ–‡ä»¶
        if include_logs:
            logs_dir = backup_path / "logs"
            logs_dir.mkdir(exist_ok=True)
            for log_file in Path(".").glob("*.log"):
                shutil.copy2(log_file, logs_dir)
        
        # å‰µå»ºå£“ç¸®åŒ…
        zip_path = f"{backup_path}.zip"
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file in backup_path.rglob('*'):
                if file.is_file():
                    zipf.write(file, file.relative_to(backup_path))
        
        # åˆªé™¤è‡¨æ™‚ç›®éŒ„
        shutil.rmtree(backup_path)
        
        return zip_path
    
    def restore_backup(self, backup_file: str, target_db_path: str) -> bool:
        """æ¢å¾©å‚™ä»½"""
        try:
            with zipfile.ZipFile(backup_file, 'r') as zipf:
                # æå–åˆ°è‡¨æ™‚ç›®éŒ„
                temp_dir = Path("temp_restore")
                zipf.extractall(temp_dir)
                
                # æ¢å¾©æ•¸æ“šåº«
                db_backup = temp_dir / "database.db"
                if db_backup.exists():
                    shutil.copy2(db_backup, target_db_path)
                
                # æ¸…ç†è‡¨æ™‚ç›®éŒ„
                shutil.rmtree(temp_dir)
                
                return True
        except Exception as e:
            print(f"æ¢å¾©å¤±æ•—: {e}")
            return False
    
    def auto_backup_scheduler(self, db_path: str, interval_hours: int = 24):
        """è‡ªå‹•å‚™ä»½èª¿åº¦å™¨"""
        import schedule
        
        def backup_job():
            try:
                backup_file = self.create_backup(db_path)
                print(f"è‡ªå‹•å‚™ä»½å®Œæˆ: {backup_file}")
                
                # æ¸…ç†èˆŠå‚™ä»½ï¼ˆä¿ç•™æœ€è¿‘7å€‹ï¼‰
                self._cleanup_old_backups(keep_count=7)
            except Exception as e:
                print(f"è‡ªå‹•å‚™ä»½å¤±æ•—: {e}")
        
        schedule.every(interval_hours).hours.do(backup_job)
    
    def _cleanup_old_backups(self, keep_count: int = 7):
        """æ¸…ç†èˆŠå‚™ä»½"""
        backups = sorted(self.backup_dir.glob("backup_*.zip"))
        
        if len(backups) > keep_count:
            for backup in backups[:-keep_count]:
                backup.unlink()

# audit_logger.py - å¯©è¨ˆæ—¥èªŒ

class AuditLogger:
    """å¯©è¨ˆæ—¥èªŒç³»çµ±"""
    
    def __init__(self, log_file: str = "audit.log"):
        self.log_file = log_file
        
    def log_event(self, event_type: str, user_id: int, details: Dict):
        """è¨˜éŒ„å¯©è¨ˆäº‹ä»¶"""
        event = {
            'timestamp': datetime.now().isoformat(),
            'event_type': event_type,
            'user_id': user_id,
            'details': details
        }
        
        with open(self.log_file, 'a') as f:
            f.write(json.dumps(event) + '\n')
    
    def log_order(self, user_id: int, order_id: int, product_id: int, amount: float):
        """è¨˜éŒ„è¨‚å–®äº‹ä»¶"""
        self.log_event('order_created', user_id, {
            'order_id': order_id,
            'product_id': product_id,
            'amount': amount
        })
    
    def log_payment(self, user_id: int, order_id: int, method: str, status: str):
        """è¨˜éŒ„æ”¯ä»˜äº‹ä»¶"""
        self.log_event('payment', user_id, {
            'order_id': order_id,
            'method': method,
            'status': status
        })
    
    def log_admin_action(self, admin_id: int, action: str, target: str):
        """è¨˜éŒ„ç®¡ç†å“¡æ“ä½œ"""
        self.log_event('admin_action', admin_id, {
            'action': action,
            'target': target
        })
    
    def get_user_history(self, user_id: int) -> List[Dict]:
        """ç²å–ç”¨æˆ¶æ­·å²è¨˜éŒ„"""
        history = []
        
        with open(self.log_file, 'r') as f:
            for line in f:
                event = json.loads(line.strip())
                if event['user_id'] == user_id:
                    history.append(event)
        
        return history